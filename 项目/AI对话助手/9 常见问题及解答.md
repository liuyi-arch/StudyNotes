# 对话助手项目

**项目简介**：基于 Google Gemini API 的智能对话平台，支持文本和语音输入，具备多轮对话、历史记录管理、打字动画等功能，提供类 ChatGPT 的自然语言交互体验。

**技术栈**：React、Vite、Google Gemini API、Web Speech API、React Context；

项目工作：

- 搭建基于 React + Vite 的模块化工程，采用函数组件与 Hooks 编写核心逻辑，使用 React Context 管理会话、语音状态等全局数据；
- 封装 gemini.js 模块，实现 Gemini API 的上下文对话流控制，统一消息请求、流式响应处理与异常重试机制；
- 开发语音输入子模块，基于 Web Speech API 实现麦克风录制控制、语音转写、交互反馈提示等复杂交互组件；
- 构建对话历史持久化机制，结合 localStorage 与 Context 管理消息缓存，支持历史对话回溯、删除等多种操作。

1. **你是如何与 Google Gemini API 对接的？使用的是什么通信方式？**

   1.1 follow-up：请求是否支持流式响应？你是怎么处理响应数据的？

   - 通过官方的 **`@google/generative-ai` JavaScript SDK** 与 Gemini API 对接；使用的通信方式是基于 HTTPS 的异步函数调用；

     - 使用 API 密钥初始化 `GoogleGenerativeAI`客户端，获取指定的生成模型，然后调用`chat.sendMessage(prompt)`方法来发送用户输入并接收回复；

       ```js
       async function runChat(prompt) {
         const genAI = new GoogleGenerativeAI(API_KEY);
         const model = genAI.getGenerativeModel({ model: MODEL_NAME });
       	// ...
         const chat = model.startChat({
           generationConfig,
           safetySettings,
           history: []
         });
       
         const result = await chat.sendMessage(prompt);
         const response = result.response;
         return response.text();
       }
       ```

   - 当前暂未使用 API 级别的流式响应，而是通过`await chat.sendMessage(prompt)`等待 API 返回完整的响应，但是在**前端模拟了流式效果**；

     - 利用 `setTimeout`创造出一种打字机动画效果；

       ```js
       const ContextProvider = (props) =>{
       	// ...
           const deplayPara = (index, nextWord)   =>{
               setTimeout(function(){
                   setResultData(prev=>prev +nextWord)
               },75*index)
           }
       	// ...
       }
       ```

       `deplayPara`函数接收一个单词和其索引，然后通过 setTimeout让这个单词在 75 * index毫秒的延迟后再追加到结果字符串中；

       > `generateContentStream()`：支持流式响应，可以实时接收模型生成的 token；

2. **你是如何管理多轮对话上下文的？上下文信息是怎么维护的？**

   2.1 follow-up：有没有做过对上下文长度或轮数的限制？为什么？

   - 对话历史在客户端的 React Context 中进行管理；使用`prevPrompt`存储用户输入过的历史记录；

     ```js
     const [prevPrompt,setPrevprompt] = useState([]);
     ```

     > - **没有真正的上下文**：每次发送给 API 的请求都被视为一个全新的、独立的对话；
     >
     > - **没有施加限制**；

3. **Web Speech API 是如何实现语音转文字的？兼容性如何？**

   3.1 follow-up：是否考虑了用户语音输入中的暂停、错误识别等边界情况？

   - 使用的Web Speech API 是 `new window.webkitSpeechRecognition()`；
     - 通过`new window.webkitSpeechRecognition()`创建了一个 `recognition`对象，并为其定义了 onresult和 onend事件的处理函数；
     - 当用户点击语音按钮时，调用 `recognition.start()`；
     - 当检测到语音并识别结束后，onresult 事件被触发，代码从中提取出文本，并将其作为 prompt 发送；
   - 使用的是webkit带前缀版本的Web Speech API ，对基于 Blink 内核的浏览器（比如Chrome、Edge）兼容性良好，对于Firefox和safari kennel需要使用替换方案比如polyfill；
   - 暂停：如果用户说话时有明显停顿，浏览器的语音识别会触发 onend事件，从而停止录音；

4. **你们项目的状态管理用的是什么？为什么选择 React Context 而不是 Zustand、Redux？**

   - 使用的是**React 内置的 Context API** 进行状态管理；
   - 状态逻辑并不复杂，简单够用；

5. **项目中打字动画效果是如何实现的？是纯 CSS 还是 JavaScript 控制？是否支持打断或跳过？**

6. **你如何处理聊天记录的持久化？用的是哪种本地存储方案？是否考虑了数据量大的场景？**

   - 没有持久化处理：聊天记录（prevPrompt）和当前的对话内容（recentPrompt, resultData）都存储在 React 的useState中；用户刷新页面或关闭标签页时，所有的聊天记录都会丢失；

     > - 中小型数据量，可以使用 localStorage；
     >   - 可以引入一个 useEffect，当 prevPrompt发生变化时，就用`localStorage.setItem('chat_history', JSON.stringify(prevPrompt))`将其存入本地。在组件初始化时，再从 `localStorage.getItem`读取并设置为 useState的初始值；
     > - 客户端数据库方案，如 **`IndexedDB`**；

7. **你在实现打字动画、语音录制动画时，有没有遇到过性能瓶颈？如何解决？**

   - 当前打字机动画采用setTimeout实现，对于非常长的文本，可能会出现 UI 卡顿或动画不流畅情况；

     > - 可以使用 requestAnimationFrame来代替 setTimeout；
     >
     > - 将动画逻辑改为在一个requestAnimationFrame循环中逐帧更新文本内容；
     >
     > - requestAnimationFrame会告诉浏览器在下一次重绘之前执行回调，它的执行时机由浏览器优化，可以确保动画的流畅性；

8. **是否做过消息节流、防抖处理？比如输入框、语音提交等操作上。**

   - 可以对发送按钮上绑定的 onSent函数应用**防抖**处理。

     > 例如，使用use-debounce库或自定义一个 useDebounce Hook，确保用户在短时间内多次点击发送按钮时，只执行最后一次调用；

9. **项目中模块如何划分？AI 请求、语音、界面是如何解耦的？**

   - **`src/config` (配置层)**：负责与外部服务（Gemini API）的连接和配置；
   - **`src/context` (逻辑/状态层)**：负责管理所有共享状态和核心业务逻辑（如发送消息、处理语音、维护历史记录）；
   - **`src/components` (表现层)**：负责 UI 的渲染；Main组件和SidBar组件；

   - UI 组件不直接调用 gemini.js，也不自己维护全局状态。它们只与 Context 交互，消费状态和调用方法。这使得 AI 请求、语音逻辑和界面可以独立修改和测试；

10. **是否有统一封装 API 请求模块？请求失败如何处理？有没有做重试机制？**

    - runChat 函数可以看作是一个**基础的 API 请求模块封装**。它将模型初始化、配置和发送消息的逻辑聚合在一起。
      - 可以在 onSent函数中使用 try...catch来包裹 await runChat(...)；如果 API 请求因为网络问题、API 密钥无效等原因，在 catch块中，可以抛出对应错误状态；
      - 在 catch块中，可以检查错误的类型（如是否是网络超时），如果符合重试条件，则可以等待一小段时间后再次调用；

11. **聊天组件是如何设计的？~~是否可复用？支持其他消息类型吗（如图片、按钮）~~**

    - 分为Main和SideBar两个部分，分别是主聊天界面、侧边栏，用于显示历史记录；

    - 通过 useContext(Context)直接从全局状态管理中获取了所有需要的数据（如 recentPrompt,resultData, loading）和操作函数（如 onSent, setInput）；

    - 通过 showResult这个布尔值来切换两种完全不同的界面状态：初始的欢迎界面和显示聊天结果的界面；

      > - **不可复用**。由于它与 Context紧密耦合，除非把整个 Context的逻辑也一起迁移到另外一个项目中；
      > - 只支持渲染纯文本和通过 dangerouslySetInnerHTML渲染简单的 HTML 字符串；

12. **性能优化的所有指标都要了解，例如首屏渲染时间 (FCP)、最大内容绘制 (LCP)、首字节时间 (TTFB) 等，具体有哪些优化手段？**

    - **TTFB (Time to First Byte)**：首字节时间，衡量服务器响应速度；

      - 使用 **CDN** 来缓存静态资源（HTML, JS, CSS），让用户从最近的节点加载；~~数据库查询优化；~~

        > 静态资源（如图片、CSS、JavaScript 文件）部署到 CDN 上后，当用户访问您的网站时，CDN 会智能地让**离用户物理位置最近的服务器**来响应请求，而不是从您的源服务器（可能在很远的地方）获取；

    - **FCP (First Contentful Paint)**：首次内容绘制，衡量浏览器渲染出第一个 DOM 元素的时间；

      - **减少阻塞渲染的资源**，例如将 `<script>`标签加上 defer 或 async属性；将关键 CSS 内联到 HTML 的 `<head>`中，非关键 CSS 异步加载；压缩 HTML/CSS/JS 文件大小；

    - **LCP (Largest Contentful Paint)**：最大内容绘制，衡量视口中最大的图片或文本块渲染完成的时间；

      - **优化 LCP 元素本身**：如果 LCP 元素是图片，需要对其进行压缩、使用现代格式（如WebP/AVIF）；并使用 srcset提供响应式图片；**预加载（preload）** LCP 图片资源；避免使用 JS 来加载 LCP 元素，让 LCP 元素作为**纯粹的 HTML `<img>` 标签**直接存在于从服务器返回的初始 HTML 文档中；

        > - 图片的下载与页面的解析并行进行：在 HTML 的 `<head>`中加入 `<link rel="preload" as="image" href="/path/to/lcp-image.webp">`；

    - **FID (First Input Delay) / INP (Interaction to Next Paint)**：首次输入延迟 / 下次绘制交互，衡量用户首次交互（如点击）到浏览器响应的延迟；

      - **减少主线程的工作量**：代码分割（Code Splitting），将不需要立即执行的 JS 分离出去；使用 Web Workers 将耗时长的计算任务放到后台线程；

    - **CLS (Cumulative Layout Shift)**：累积布局偏移，衡量视觉稳定性；

      - 对于动态加载的 UI，预留好空间占位；

13. 在 React 项目中，如何优化页面加载性能？如何减少 JavaScript 打包体积，如何优化首屏渲染时间？

    减少 JavaScript 打包体积：

    - **代码分割 (Code Splitting)**：这是最重要的手段。使用 React.lazy()和 Suspense，可以将不同页面或功能模块的组件打包成独立的 JS 文件（chunks）；用户访问首页时，就只下载首页需要的 JS，而不是整个应用的 JS；
    - **Tree Shaking**：打包时自动移除代码中未被引用的部分（dead code），从而减小体积；
    - **分析打包结果**：使用 webpack-bundle-analyzer或 source-map-explorer等工具来可视化分析打包产物；帮助快速定位是哪个库或模块占用了过大的体积，从而进行针对性优化（例如，寻找更轻量的替代库）；

    优化首屏渲染时间：

    - **服务端渲染 (SSR - Server-Side Rendering)**：使用比如 Next.js 框架；服务器直接将 React 组件渲染成完整的 HTML 字符串，然后发送给浏览器；浏览器接收到 HTML 后可以立即显示页面内容，无需等待 JS 下载和执行；
    - 将关键 CSS 内联，非关键 CSS 和 JS 异步加载，使用 preload预加载 LCP 资源；
    - **使用骨架屏 (Skeleton Screens)**：在等待真实数据返回时，先显示一个页面的大致轮廓（骨架屏）；
